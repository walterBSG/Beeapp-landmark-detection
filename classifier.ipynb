{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint, shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(y_test, y_pred):\n",
    "    counter = 0\n",
    "    for test, pred in zip(y_test, y_pred):\n",
    "        if test == pred:\n",
    "            counter += 1\n",
    "\n",
    "    print(counter/len(y_pred))\n",
    "    \n",
    "def take_random(lis, n):\n",
    "    new_vec = []\n",
    "    for _ in range(n):\n",
    "        new_vec.append(lis.pop(randint(0,len(lis)-1)))\n",
    "    \n",
    "    return new_vec, lis\n",
    "    \n",
    "def new_train_test_split(X, amount):\n",
    "    first = X.loc[(X[38] == 0)]\n",
    "    first = first.drop([38],axis=1)\n",
    "    \n",
    "    second = X.loc[(X[38] == 1)]\n",
    "    second = second.drop([38],axis=1)\n",
    "    \n",
    "    other = X.loc[(X[38] > 1)]\n",
    "    \n",
    "    first = first.values.tolist()\n",
    "    second = second.values.tolist()\n",
    "    \n",
    "    s1, first = take_random(first, amount)\n",
    "    y1 = np.array([0 for i in range(amount)])\n",
    "    yfirst = np.array([0 for i in range(len(first))])\n",
    "    s2, second = take_random(second, amount)\n",
    "    y2 = np.array([1 for i in range(amount)])\n",
    "    ysecond = np.array([0 for i in range(len(second))])\n",
    "    \n",
    "    y = other[38]\n",
    "    other = other.drop([38],axis=1)\n",
    "    other = np.reshape(other, (-1,38))\n",
    "    s1 = np.reshape(s1, (-1,38))\n",
    "    s2 = np.reshape(s2, (-1,38))\n",
    "    first = np.reshape(first, (-1,38))\n",
    "    second = np.reshape(second, (-1,38))\n",
    "    y = np.reshape(y, (-1))\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(other, y, random_state=0)\n",
    "    X_train = np.vstack((X_train, s1))\n",
    "    X_train = np.vstack((X_train, s2))\n",
    "    #X_test = np.vstack((X_test, first))\n",
    "    #X_test = np.vstack((X_test, second))\n",
    "    y_train = np.concatenate([y_train, y1])\n",
    "    y_train = np.concatenate([y_train, y2])\n",
    "    y_train = np.reshape(y_train, (-1))\n",
    "    #y_test = np.concatenate([y_test, yfirst[]])\n",
    "    #y_test = np.concatenate([y_test, ysecond])\n",
    "    y_test = np.reshape(y_test, (-1))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002021</td>\n",
       "      <td>-0.353796</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>-0.396889</td>\n",
       "      <td>-0.060540</td>\n",
       "      <td>-0.346720</td>\n",
       "      <td>-0.232708</td>\n",
       "      <td>-0.247090</td>\n",
       "      <td>-0.184139</td>\n",
       "      <td>-0.291155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492841</td>\n",
       "      <td>-0.535670</td>\n",
       "      <td>-0.371483</td>\n",
       "      <td>-0.597803</td>\n",
       "      <td>-0.410319</td>\n",
       "      <td>-0.636296</td>\n",
       "      <td>-0.410162</td>\n",
       "      <td>-0.826017</td>\n",
       "      <td>-0.310153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005608</td>\n",
       "      <td>-0.361425</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>-0.404519</td>\n",
       "      <td>-0.068170</td>\n",
       "      <td>-0.354350</td>\n",
       "      <td>-0.240338</td>\n",
       "      <td>-0.254720</td>\n",
       "      <td>-0.191769</td>\n",
       "      <td>-0.298785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500471</td>\n",
       "      <td>-0.543300</td>\n",
       "      <td>-0.379112</td>\n",
       "      <td>-0.605432</td>\n",
       "      <td>-0.417949</td>\n",
       "      <td>-0.643926</td>\n",
       "      <td>-0.417791</td>\n",
       "      <td>-0.833647</td>\n",
       "      <td>-0.317783</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.004515</td>\n",
       "      <td>-0.360332</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>-0.403425</td>\n",
       "      <td>-0.067076</td>\n",
       "      <td>-0.353256</td>\n",
       "      <td>-0.239244</td>\n",
       "      <td>-0.253626</td>\n",
       "      <td>-0.190675</td>\n",
       "      <td>-0.297691</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.499377</td>\n",
       "      <td>-0.542206</td>\n",
       "      <td>-0.378019</td>\n",
       "      <td>-0.604339</td>\n",
       "      <td>-0.416855</td>\n",
       "      <td>-0.642832</td>\n",
       "      <td>-0.416697</td>\n",
       "      <td>-0.832553</td>\n",
       "      <td>-0.316689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.006461</td>\n",
       "      <td>-0.362278</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>-0.405372</td>\n",
       "      <td>-0.069023</td>\n",
       "      <td>-0.355203</td>\n",
       "      <td>-0.241191</td>\n",
       "      <td>-0.255573</td>\n",
       "      <td>-0.192622</td>\n",
       "      <td>-0.299638</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.501324</td>\n",
       "      <td>-0.544153</td>\n",
       "      <td>-0.379965</td>\n",
       "      <td>-0.606285</td>\n",
       "      <td>-0.418802</td>\n",
       "      <td>-0.644779</td>\n",
       "      <td>-0.418644</td>\n",
       "      <td>-0.834500</td>\n",
       "      <td>-0.318636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004465</td>\n",
       "      <td>-0.351352</td>\n",
       "      <td>0.016610</td>\n",
       "      <td>-0.394445</td>\n",
       "      <td>-0.058096</td>\n",
       "      <td>-0.344276</td>\n",
       "      <td>-0.230264</td>\n",
       "      <td>-0.244646</td>\n",
       "      <td>-0.181695</td>\n",
       "      <td>-0.288711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.490397</td>\n",
       "      <td>-0.533226</td>\n",
       "      <td>-0.369039</td>\n",
       "      <td>-0.595359</td>\n",
       "      <td>-0.407875</td>\n",
       "      <td>-0.633852</td>\n",
       "      <td>-0.407718</td>\n",
       "      <td>-0.823573</td>\n",
       "      <td>-0.307709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.002021 -0.353796  0.014166 -0.396889 -0.060540 -0.346720 -0.232708   \n",
       "1 -0.005608 -0.361425  0.006537 -0.404519 -0.068170 -0.354350 -0.240338   \n",
       "2 -0.004515 -0.360332  0.007630 -0.403425 -0.067076 -0.353256 -0.239244   \n",
       "3 -0.006461 -0.362278  0.005684 -0.405372 -0.069023 -0.355203 -0.241191   \n",
       "4  0.004465 -0.351352  0.016610 -0.394445 -0.058096 -0.344276 -0.230264   \n",
       "\n",
       "         7         8         9   ...        29        30        31        32  \\\n",
       "0 -0.247090 -0.184139 -0.291155  ... -0.492841 -0.535670 -0.371483 -0.597803   \n",
       "1 -0.254720 -0.191769 -0.298785  ... -0.500471 -0.543300 -0.379112 -0.605432   \n",
       "2 -0.253626 -0.190675 -0.297691  ... -0.499377 -0.542206 -0.378019 -0.604339   \n",
       "3 -0.255573 -0.192622 -0.299638  ... -0.501324 -0.544153 -0.379965 -0.606285   \n",
       "4 -0.244646 -0.181695 -0.288711  ... -0.490397 -0.533226 -0.369039 -0.595359   \n",
       "\n",
       "         33        34        35        36        37  38  \n",
       "0 -0.410319 -0.636296 -0.410162 -0.826017 -0.310153   0  \n",
       "1 -0.417949 -0.643926 -0.417791 -0.833647 -0.317783   0  \n",
       "2 -0.416855 -0.642832 -0.416697 -0.832553 -0.316689   0  \n",
       "3 -0.418802 -0.644779 -0.418644 -0.834500 -0.318636   0  \n",
       "4 -0.407875 -0.633852 -0.407718 -0.823573 -0.307709   0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testar dataset já com procrustes\n",
    "name = '/home/walter/Documents/ruttner/detections_with_procrustes.csv'\n",
    "file = pd.read_csv(name,header=None,sep='\\t')\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: 38, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = file[38]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002021</td>\n",
       "      <td>-0.353796</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>-0.396889</td>\n",
       "      <td>-0.060540</td>\n",
       "      <td>-0.346720</td>\n",
       "      <td>-0.232708</td>\n",
       "      <td>-0.247090</td>\n",
       "      <td>-0.184139</td>\n",
       "      <td>-0.291155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513367</td>\n",
       "      <td>-0.492841</td>\n",
       "      <td>-0.535670</td>\n",
       "      <td>-0.371483</td>\n",
       "      <td>-0.597803</td>\n",
       "      <td>-0.410319</td>\n",
       "      <td>-0.636296</td>\n",
       "      <td>-0.410162</td>\n",
       "      <td>-0.826017</td>\n",
       "      <td>-0.310153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005608</td>\n",
       "      <td>-0.361425</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>-0.404519</td>\n",
       "      <td>-0.068170</td>\n",
       "      <td>-0.354350</td>\n",
       "      <td>-0.240338</td>\n",
       "      <td>-0.254720</td>\n",
       "      <td>-0.191769</td>\n",
       "      <td>-0.298785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.520997</td>\n",
       "      <td>-0.500471</td>\n",
       "      <td>-0.543300</td>\n",
       "      <td>-0.379112</td>\n",
       "      <td>-0.605432</td>\n",
       "      <td>-0.417949</td>\n",
       "      <td>-0.643926</td>\n",
       "      <td>-0.417791</td>\n",
       "      <td>-0.833647</td>\n",
       "      <td>-0.317783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.004515</td>\n",
       "      <td>-0.360332</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>-0.403425</td>\n",
       "      <td>-0.067076</td>\n",
       "      <td>-0.353256</td>\n",
       "      <td>-0.239244</td>\n",
       "      <td>-0.253626</td>\n",
       "      <td>-0.190675</td>\n",
       "      <td>-0.297691</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.519903</td>\n",
       "      <td>-0.499377</td>\n",
       "      <td>-0.542206</td>\n",
       "      <td>-0.378019</td>\n",
       "      <td>-0.604339</td>\n",
       "      <td>-0.416855</td>\n",
       "      <td>-0.642832</td>\n",
       "      <td>-0.416697</td>\n",
       "      <td>-0.832553</td>\n",
       "      <td>-0.316689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.006461</td>\n",
       "      <td>-0.362278</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>-0.405372</td>\n",
       "      <td>-0.069023</td>\n",
       "      <td>-0.355203</td>\n",
       "      <td>-0.241191</td>\n",
       "      <td>-0.255573</td>\n",
       "      <td>-0.192622</td>\n",
       "      <td>-0.299638</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.521850</td>\n",
       "      <td>-0.501324</td>\n",
       "      <td>-0.544153</td>\n",
       "      <td>-0.379965</td>\n",
       "      <td>-0.606285</td>\n",
       "      <td>-0.418802</td>\n",
       "      <td>-0.644779</td>\n",
       "      <td>-0.418644</td>\n",
       "      <td>-0.834500</td>\n",
       "      <td>-0.318636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004465</td>\n",
       "      <td>-0.351352</td>\n",
       "      <td>0.016610</td>\n",
       "      <td>-0.394445</td>\n",
       "      <td>-0.058096</td>\n",
       "      <td>-0.344276</td>\n",
       "      <td>-0.230264</td>\n",
       "      <td>-0.244646</td>\n",
       "      <td>-0.181695</td>\n",
       "      <td>-0.288711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510923</td>\n",
       "      <td>-0.490397</td>\n",
       "      <td>-0.533226</td>\n",
       "      <td>-0.369039</td>\n",
       "      <td>-0.595359</td>\n",
       "      <td>-0.407875</td>\n",
       "      <td>-0.633852</td>\n",
       "      <td>-0.407718</td>\n",
       "      <td>-0.823573</td>\n",
       "      <td>-0.307709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.002021 -0.353796  0.014166 -0.396889 -0.060540 -0.346720 -0.232708   \n",
       "1 -0.005608 -0.361425  0.006537 -0.404519 -0.068170 -0.354350 -0.240338   \n",
       "2 -0.004515 -0.360332  0.007630 -0.403425 -0.067076 -0.353256 -0.239244   \n",
       "3 -0.006461 -0.362278  0.005684 -0.405372 -0.069023 -0.355203 -0.241191   \n",
       "4  0.004465 -0.351352  0.016610 -0.394445 -0.058096 -0.344276 -0.230264   \n",
       "\n",
       "         7         8         9   ...        28        29        30        31  \\\n",
       "0 -0.247090 -0.184139 -0.291155  ... -0.513367 -0.492841 -0.535670 -0.371483   \n",
       "1 -0.254720 -0.191769 -0.298785  ... -0.520997 -0.500471 -0.543300 -0.379112   \n",
       "2 -0.253626 -0.190675 -0.297691  ... -0.519903 -0.499377 -0.542206 -0.378019   \n",
       "3 -0.255573 -0.192622 -0.299638  ... -0.521850 -0.501324 -0.544153 -0.379965   \n",
       "4 -0.244646 -0.181695 -0.288711  ... -0.510923 -0.490397 -0.533226 -0.369039   \n",
       "\n",
       "         32        33        34        35        36        37  \n",
       "0 -0.597803 -0.410319 -0.636296 -0.410162 -0.826017 -0.310153  \n",
       "1 -0.605432 -0.417949 -0.643926 -0.417791 -0.833647 -0.317783  \n",
       "2 -0.604339 -0.416855 -0.642832 -0.416697 -0.832553 -0.316689  \n",
       "3 -0.606285 -0.418802 -0.644779 -0.418644 -0.834500 -0.318636  \n",
       "4 -0.595359 -0.407875 -0.633852 -0.407718 -0.823573 -0.307709  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = file.drop([38],axis=1)\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X)\n",
    "#X = scaler.transform(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "      <td>7527.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000115</td>\n",
       "      <td>-0.355932</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.399026</td>\n",
       "      <td>-0.062677</td>\n",
       "      <td>-0.348857</td>\n",
       "      <td>-0.234845</td>\n",
       "      <td>-0.249227</td>\n",
       "      <td>-0.186276</td>\n",
       "      <td>-0.293292</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.515504</td>\n",
       "      <td>-0.494978</td>\n",
       "      <td>-0.537807</td>\n",
       "      <td>-0.373619</td>\n",
       "      <td>-0.599939</td>\n",
       "      <td>-0.412456</td>\n",
       "      <td>-0.638433</td>\n",
       "      <td>-0.412298</td>\n",
       "      <td>-0.828154</td>\n",
       "      <td>-0.312289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.008528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.204073</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-0.191928</td>\n",
       "      <td>-0.602983</td>\n",
       "      <td>-0.266634</td>\n",
       "      <td>-0.552814</td>\n",
       "      <td>-0.438802</td>\n",
       "      <td>-0.453184</td>\n",
       "      <td>-0.390233</td>\n",
       "      <td>-0.497249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.719461</td>\n",
       "      <td>-0.698935</td>\n",
       "      <td>-0.741764</td>\n",
       "      <td>-0.577577</td>\n",
       "      <td>-0.803897</td>\n",
       "      <td>-0.616413</td>\n",
       "      <td>-0.842390</td>\n",
       "      <td>-0.616255</td>\n",
       "      <td>-1.032111</td>\n",
       "      <td>-0.516247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.003264</td>\n",
       "      <td>-0.359081</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>-0.402175</td>\n",
       "      <td>-0.065826</td>\n",
       "      <td>-0.352006</td>\n",
       "      <td>-0.237994</td>\n",
       "      <td>-0.252376</td>\n",
       "      <td>-0.189425</td>\n",
       "      <td>-0.296441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.518653</td>\n",
       "      <td>-0.498127</td>\n",
       "      <td>-0.540956</td>\n",
       "      <td>-0.376768</td>\n",
       "      <td>-0.603088</td>\n",
       "      <td>-0.415605</td>\n",
       "      <td>-0.641582</td>\n",
       "      <td>-0.415447</td>\n",
       "      <td>-0.831303</td>\n",
       "      <td>-0.315439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000516</td>\n",
       "      <td>-0.356333</td>\n",
       "      <td>0.011629</td>\n",
       "      <td>-0.399427</td>\n",
       "      <td>-0.063078</td>\n",
       "      <td>-0.349258</td>\n",
       "      <td>-0.235246</td>\n",
       "      <td>-0.249628</td>\n",
       "      <td>-0.186677</td>\n",
       "      <td>-0.293693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.515905</td>\n",
       "      <td>-0.495379</td>\n",
       "      <td>-0.538208</td>\n",
       "      <td>-0.374020</td>\n",
       "      <td>-0.600340</td>\n",
       "      <td>-0.412857</td>\n",
       "      <td>-0.638834</td>\n",
       "      <td>-0.412699</td>\n",
       "      <td>-0.828555</td>\n",
       "      <td>-0.312690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.002130</td>\n",
       "      <td>-0.353687</td>\n",
       "      <td>0.014275</td>\n",
       "      <td>-0.396780</td>\n",
       "      <td>-0.060431</td>\n",
       "      <td>-0.346612</td>\n",
       "      <td>-0.232599</td>\n",
       "      <td>-0.246982</td>\n",
       "      <td>-0.184030</td>\n",
       "      <td>-0.291046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513259</td>\n",
       "      <td>-0.492733</td>\n",
       "      <td>-0.535562</td>\n",
       "      <td>-0.371374</td>\n",
       "      <td>-0.597694</td>\n",
       "      <td>-0.410211</td>\n",
       "      <td>-0.636188</td>\n",
       "      <td>-0.410053</td>\n",
       "      <td>-0.825909</td>\n",
       "      <td>-0.310044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.157474</td>\n",
       "      <td>-0.198343</td>\n",
       "      <td>0.169619</td>\n",
       "      <td>-0.241436</td>\n",
       "      <td>0.094913</td>\n",
       "      <td>-0.191268</td>\n",
       "      <td>-0.077255</td>\n",
       "      <td>-0.091637</td>\n",
       "      <td>-0.028686</td>\n",
       "      <td>-0.135702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.357914</td>\n",
       "      <td>-0.337388</td>\n",
       "      <td>-0.380217</td>\n",
       "      <td>-0.216030</td>\n",
       "      <td>-0.442350</td>\n",
       "      <td>-0.254867</td>\n",
       "      <td>-0.480843</td>\n",
       "      <td>-0.254709</td>\n",
       "      <td>-0.670564</td>\n",
       "      <td>-0.154700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  7527.000000  7527.000000  7527.000000  7527.000000  7527.000000   \n",
       "mean     -0.000115    -0.355932     0.012030    -0.399026    -0.062677   \n",
       "std       0.008528     0.008528     0.008528     0.008528     0.008528   \n",
       "min      -0.204073    -0.559889    -0.191928    -0.602983    -0.266634   \n",
       "25%      -0.003264    -0.359081     0.008881    -0.402175    -0.065826   \n",
       "50%      -0.000516    -0.356333     0.011629    -0.399427    -0.063078   \n",
       "75%       0.002130    -0.353687     0.014275    -0.396780    -0.060431   \n",
       "max       0.157474    -0.198343     0.169619    -0.241436     0.094913   \n",
       "\n",
       "                5            6            7            8            9   ...  \\\n",
       "count  7527.000000  7527.000000  7527.000000  7527.000000  7527.000000  ...   \n",
       "mean     -0.348857    -0.234845    -0.249227    -0.186276    -0.293292  ...   \n",
       "std       0.008528     0.008528     0.008528     0.008528     0.008528  ...   \n",
       "min      -0.552814    -0.438802    -0.453184    -0.390233    -0.497249  ...   \n",
       "25%      -0.352006    -0.237994    -0.252376    -0.189425    -0.296441  ...   \n",
       "50%      -0.349258    -0.235246    -0.249628    -0.186677    -0.293693  ...   \n",
       "75%      -0.346612    -0.232599    -0.246982    -0.184030    -0.291046  ...   \n",
       "max      -0.191268    -0.077255    -0.091637    -0.028686    -0.135702  ...   \n",
       "\n",
       "                28           29           30           31           32  \\\n",
       "count  7527.000000  7527.000000  7527.000000  7527.000000  7527.000000   \n",
       "mean     -0.515504    -0.494978    -0.537807    -0.373619    -0.599939   \n",
       "std       0.008528     0.008528     0.008528     0.008528     0.008528   \n",
       "min      -0.719461    -0.698935    -0.741764    -0.577577    -0.803897   \n",
       "25%      -0.518653    -0.498127    -0.540956    -0.376768    -0.603088   \n",
       "50%      -0.515905    -0.495379    -0.538208    -0.374020    -0.600340   \n",
       "75%      -0.513259    -0.492733    -0.535562    -0.371374    -0.597694   \n",
       "max      -0.357914    -0.337388    -0.380217    -0.216030    -0.442350   \n",
       "\n",
       "                33           34           35           36           37  \n",
       "count  7527.000000  7527.000000  7527.000000  7527.000000  7527.000000  \n",
       "mean     -0.412456    -0.638433    -0.412298    -0.828154    -0.312289  \n",
       "std       0.008528     0.008528     0.008528     0.008528     0.008528  \n",
       "min      -0.616413    -0.842390    -0.616255    -1.032111    -0.516247  \n",
       "25%      -0.415605    -0.641582    -0.415447    -0.831303    -0.315439  \n",
       "50%      -0.412857    -0.638834    -0.412699    -0.828555    -0.312690  \n",
       "75%      -0.410211    -0.636188    -0.410053    -0.825909    -0.310044  \n",
       "max      -0.254867    -0.480843    -0.254709    -0.670564    -0.154700  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set\n",
    "#X = np.reshape(X, (-1,38))\n",
    "#y = np.reshape(y, (-1))\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "#new split\n",
    "X_train, X_test, y_train, y_test = new_train_test_split(file, 200)\n",
    "#print(len(X_train),len((y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06493506493506493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walter/anaconda3/envs/w/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "classifier = svm.LinearSVC(C = 100)\n",
    "y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "dump(classifier, 'SVM.joblib')\n",
    "compare(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04112554112554113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "dump(classifier, 'Naive.joblib')\n",
    "compare(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05194805194805195\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, max_depth=4, random_state=0)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "dump(clf, 'random_forest.joblib')\n",
    "compare(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1428 samples, validate on 358 samples\n",
      "Epoch 1/20\n",
      "1428/1428 [==============================] - 1s 829us/step - loss: 3.3631 - acc: 0.0504 - val_loss: 3.4122 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "1428/1428 [==============================] - 0s 18us/step - loss: 3.3384 - acc: 0.0476 - val_loss: 3.4421 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "1428/1428 [==============================] - 0s 15us/step - loss: 3.3052 - acc: 0.0567 - val_loss: 3.4717 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "1428/1428 [==============================] - 0s 18us/step - loss: 3.2918 - acc: 0.0770 - val_loss: 3.5150 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "1428/1428 [==============================] - 0s 18us/step - loss: 3.2748 - acc: 0.0784 - val_loss: 3.5637 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "1428/1428 [==============================] - 0s 17us/step - loss: 3.2543 - acc: 0.0882 - val_loss: 3.6186 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "1428/1428 [==============================] - 0s 17us/step - loss: 3.2393 - acc: 0.0805 - val_loss: 3.6831 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "1428/1428 [==============================] - 0s 15us/step - loss: 3.2245 - acc: 0.0910 - val_loss: 3.7459 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "1428/1428 [==============================] - 0s 19us/step - loss: 3.2111 - acc: 0.0959 - val_loss: 3.8156 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "1428/1428 [==============================] - 0s 17us/step - loss: 3.2129 - acc: 0.0973 - val_loss: 3.8674 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "1428/1428 [==============================] - 0s 19us/step - loss: 3.2059 - acc: 0.1008 - val_loss: 3.9052 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "1428/1428 [==============================] - 0s 17us/step - loss: 3.1907 - acc: 0.0924 - val_loss: 3.9398 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "1428/1428 [==============================] - 0s 17us/step - loss: 3.1864 - acc: 0.1008 - val_loss: 3.9625 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "1428/1428 [==============================] - 0s 20us/step - loss: 3.1809 - acc: 0.0952 - val_loss: 3.9829 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "1428/1428 [==============================] - 0s 17us/step - loss: 3.1793 - acc: 0.0889 - val_loss: 4.0085 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "1428/1428 [==============================] - 0s 17us/step - loss: 3.1795 - acc: 0.0917 - val_loss: 4.0283 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "1428/1428 [==============================] - 0s 22us/step - loss: 3.1723 - acc: 0.0980 - val_loss: 4.0434 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "1428/1428 [==============================] - 0s 16us/step - loss: 3.1563 - acc: 0.0973 - val_loss: 4.0754 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "1428/1428 [==============================] - 0s 18us/step - loss: 3.1605 - acc: 0.0994 - val_loss: 4.1169 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "1428/1428 [==============================] - 0s 21us/step - loss: 3.1538 - acc: 0.0938 - val_loss: 4.1528 - val_acc: 0.0000e+00\n",
      "462/462 [==============================] - 0s 12us/step\n",
      "[3.086490570208727, 0.08658008706389052]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "y_train_net = keras.utils.to_categorical(y_train, num_classes=28, dtype='float32')\n",
    "y_test_net = keras.utils.to_categorical(y_test, num_classes=28, dtype='float32')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=38))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(28, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_net, epochs=20, batch_size=256, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(X_test, y_test_net, batch_size=128)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
